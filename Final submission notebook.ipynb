{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48d1c9f",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8b15ad",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dfb7836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.32.5)\n",
      "Requirement already satisfied: selenium in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.38.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from bs4) (4.14.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: trio<1.0,>=0.31.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (0.32.0)\n",
      "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from beautifulsoup4->bs4) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4 requests selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "042302ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Web Requests\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Web Scraping\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Web Automation (Selenium)\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "from IPython.display import display\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7387703",
   "metadata": {},
   "source": [
    "### What this code does\n",
    "\n",
    "- **Defines datasets to download**: A list of NGER dataset IDs (`ID0075` … `ID0243`) is specified.\n",
    "- **Builds the API endpoint**: Uses a base OData URL with a `select=*` query to fetch full records for each dataset ID.\n",
    "- **Prepares an output folder**: Resolves the current file’s directory, creates `data/source 1/Data` if it doesn’t exist.\n",
    "- **Downloads each dataset**:\n",
    "  - Sends an HTTP GET to the dataset-specific URL.\n",
    "  - On HTTP 200:\n",
    "    - Parses the response as JSON.\n",
    "    - Supports two shapes:\n",
    "      - An object with a `value` array.\n",
    "      - A top-level array.\n",
    "    - Converts the records into a Pandas DataFrame.\n",
    "    - Saves the data as a CSV named `NGER.IDXXXX.csv` in `data/source 1/Data`.\n",
    "    - Prints a success message.\n",
    "  - On non-200 or JSON/processing error:\n",
    "    - Prints a failure message with status code or exception details.\n",
    "\n",
    "### Key behaviors and safeguards\n",
    "\n",
    "- **Flexible JSON handling**: Works whether the API returns `{ \"value\": [...] }` or a plain list.\n",
    "- **Idempotent directory creation**: Uses `os.makedirs(..., exist_ok=True)` to avoid errors if the folder already exists.\n",
    "- **Per-dataset error reporting**: Continues through the list even if one dataset fails, logging the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0873a54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ineerajrajeev/Desktop/Assignment 2 DE/data/NGER.ID0075.csv saved successfully.\n",
      "/Users/ineerajrajeev/Desktop/Assignment 2 DE/data/NGER.ID0076.csv saved successfully.\n",
      "/Users/ineerajrajeev/Desktop/Assignment 2 DE/data/NGER.ID0077.csv saved successfully.\n",
      "/Users/ineerajrajeev/Desktop/Assignment 2 DE/data/NGER.ID0078.csv saved successfully.\n",
      "/Users/ineerajrajeev/Desktop/Assignment 2 DE/data/NGER.ID0079.csv saved successfully.\n",
      "/Users/ineerajrajeev/Desktop/Assignment 2 DE/data/NGER.ID0080.csv saved successfully.\n",
      "/Users/ineerajrajeev/Desktop/Assignment 2 DE/data/NGER.ID0081.csv saved successfully.\n",
      "/Users/ineerajrajeev/Desktop/Assignment 2 DE/data/NGER.ID0082.csv saved successfully.\n",
      "/Users/ineerajrajeev/Desktop/Assignment 2 DE/data/NGER.ID0083.csv saved successfully.\n",
      "/Users/ineerajrajeev/Desktop/Assignment 2 DE/data/NGER.ID0243.csv saved successfully.\n"
     ]
    }
   ],
   "source": [
    "dataset_ids = [\"ID0075\", \"ID0076\", \"ID0077\", \"ID0078\", \"ID0079\",\n",
    "               \"ID0080\", \"ID0081\", \"ID0082\", \"ID0083\", \"ID0243\"]\n",
    "\n",
    "base_url = \"https://api.cer.gov.au/datahub-public/v1/api/ODataDataset/NGER/dataset/{}?select%3D%2A\"\n",
    "cwd = os.getcwd()\n",
    "data_folder = os.path.join(cwd, \"data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "for dataset_id in dataset_ids:\n",
    "    url = base_url.format(dataset_id)\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            data = response.json()  # Parse JSON\n",
    "            \n",
    "            # Handle both dict with \"value\" key or list directly\n",
    "            if isinstance(data, dict) and \"value\" in data:\n",
    "                records = data[\"value\"]\n",
    "            elif isinstance(data, list):\n",
    "                records = data\n",
    "            else:\n",
    "                records = []\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(records)\n",
    "            \n",
    "            # Save as actual CSV\n",
    "            file_path = os.path.join(data_folder, f\"NGER.{dataset_id}.csv\")\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"{file_path} saved successfully.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to parse dataset {dataset_id}: {e}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {dataset_id}, status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4e639a",
   "metadata": {},
   "source": [
    "### What this code does\n",
    "\n",
    "- **Initializes workspace**: Sets `cwd` to the current working directory, ensures a `data` folder exists.\n",
    "- **Configures headless browser**: Starts Chrome in headless mode with a tall window to load expandable content.\n",
    "- **Navigates to target page**: Opens the CER Large-scale Renewable Energy data page and waits for elements.\n",
    "\n",
    "### Interaction and scraping flow\n",
    "\n",
    "- **Expands hidden sections**: Finds all “Show” buttons under “About this Table” and clicks each to reveal content, with scroll-into-view and retries per button.\n",
    "- **Finds relevant links**:\n",
    "  - Searches for anchors whose `href` starts with `/document`.\n",
    "  - Filters by link text containing:\n",
    "    - “Power stations and projects – accredited”\n",
    "    - “Power stations and projects – committed”\n",
    "    - “Power stations and projects – probable”\n",
    "  - Normalizes to absolute URLs and deduplicates.\n",
    "- **Downloads files**:\n",
    "  - For each matched link, performs an HTTP GET.\n",
    "  - On 200 OK, writes the response content to the `data` folder as `<last-path-segment>.csv`.\n",
    "  - Logs success or failure per file.\n",
    "\n",
    "### Error handling and cleanup\n",
    "\n",
    "- **Resilient clicking**: Logs and skips any “Show” button that fails to click; continues processing others.\n",
    "- **Graceful fallbacks**: Reports when no CSV links are found after expansion.\n",
    "- **Structured exceptions**: Catches any script-level errors and prints a clear message.\n",
    "- **Always quits browser**: Ensures `driver.quit()` runs in `finally` to close the headless browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0455373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching CER data page...\n",
      "Found 5 potential download links:\n",
      "  - [accredited] file typefile type icontotal lgcs and capacity of accredited: https://cer.gov.au/document/total-lgcs-and-capacity-accredited-power-stations-20\n",
      "  - [accredited] file typefile type icontotal lgcs and capacity of accredited: https://cer.gov.au/document/total-lgcs-and-capacity-accredited-power-stations-20\n",
      "  - [accredited] file typefile type iconpower stations and projects – accredi: https://cer.gov.au/document/power-stations-and-projects-accredited\n",
      "  - [committed] file typefile type iconpower stations and projects – committ: https://cer.gov.au/document/power-stations-and-projects-committed\n",
      "  - [probable] file typefile type iconpower stations and projects – probabl: https://cer.gov.au/document/power-stations-and-projects-probable\n",
      "\n",
      "Downloading power-stations-and-projects-accredited.csv...\n",
      "✓ Saved to /Users/ineerajrajeev/Desktop/Assignment 2 DE/data/power-stations-and-projects-accredited.csv (12546 bytes)\n",
      "\n",
      "Downloading power-stations-and-projects-accredited.csv...\n",
      "✓ Saved to /Users/ineerajrajeev/Desktop/Assignment 2 DE/data/power-stations-and-projects-accredited.csv (458 bytes)\n",
      "\n",
      "Downloading power-stations-and-projects-accredited.csv...\n",
      "✓ Saved to /Users/ineerajrajeev/Desktop/Assignment 2 DE/data/power-stations-and-projects-accredited.csv (29528 bytes)\n",
      "\n",
      "Downloading power-stations-and-projects-committed.csv...\n",
      "✓ Saved to /Users/ineerajrajeev/Desktop/Assignment 2 DE/data/power-stations-and-projects-committed.csv (1888 bytes)\n",
      "\n",
      "Downloading power-stations-and-projects-probable.csv...\n",
      "✓ Saved to /Users/ineerajrajeev/Desktop/Assignment 2 DE/data/power-stations-and-projects-probable.csv (2055 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Download CER power station files by parsing the page\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "data_folder = os.path.join(os.getcwd(), \"data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "print(\"Fetching CER data page...\")\n",
    "url = \"https://cer.gov.au/markets/reports-and-data/large-scale-renewable-energy-data\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find all links that might be CSV downloads\n",
    "    target_texts = [\n",
    "        \"accredited\",\n",
    "        \"committed\", \n",
    "        \"probable\"\n",
    "    ]\n",
    "    \n",
    "    found_links = []\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        href = link.get('href', '')\n",
    "        text = link.get_text(strip=True).lower()\n",
    "        \n",
    "        # Look for document links containing our target words\n",
    "        if '/document' in href or '.csv' in href:\n",
    "            for target in target_texts:\n",
    "                if target in text or target in href:\n",
    "                    full_url = href if href.startswith('http') else f\"https://cer.gov.au{href}\"\n",
    "                    found_links.append((target, text, full_url))\n",
    "                    break\n",
    "    \n",
    "    print(f\"Found {len(found_links)} potential download links:\")\n",
    "    for target, text, link in found_links:\n",
    "        print(f\"  - [{target}] {text[:60]}: {link[:80]}\")\n",
    "    \n",
    "    # Download the files\n",
    "    for target, text, link in found_links:\n",
    "        filename = f\"power-stations-and-projects-{target}.csv\"\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            print(f\"\\nDownloading {filename}...\")\n",
    "            r = requests.get(link, timeout=30)\n",
    "            if r.status_code == 200:\n",
    "                with open(file_path, 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                print(f\"✓ Saved to {file_path} ({len(r.content)} bytes)\")\n",
    "            else:\n",
    "                print(f\"✗ Failed, status: {r.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Error: {e}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch page, status: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8a8c673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script error: Message: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up directories\n",
    "cwd = os.getcwd()\n",
    "data_folder = os.path.join(cwd, \"data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Set up headless browser\n",
    "options = Options()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1920,4000\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://cer.gov.au/markets/reports-and-data/large-scale-renewable-energy-data\")\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "try:\n",
    "    # Click all \"Show\" buttons under \"About this Table\"\n",
    "    buttons = wait.until(EC.presence_of_all_elements_located((\n",
    "        By.XPATH, \"//button[.//div[text()='About this Table'] and .//span[text()='Show']]\"\n",
    "    )))\n",
    "    print(f\"Found {len(buttons)} 'Show' buttons. Clicking each to reveal content...\")\n",
    "\n",
    "    for idx, button in enumerate(buttons):\n",
    "        try:\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", button)\n",
    "            time.sleep(0.5)\n",
    "            driver.execute_script(\"arguments[0].click();\", button)\n",
    "            print(f\"Clicked Show button #{idx+1}\")\n",
    "            time.sleep(2)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not click Show button #{idx+1}: {e}\")\n",
    "\n",
    "    # Look for target CSV links\n",
    "    link_texts = [\n",
    "        \"Power stations and projects – accredited\",\n",
    "        \"Power stations and projects – committed\",\n",
    "        \"Power stations and projects – probable\"\n",
    "    ]\n",
    "\n",
    "    anchors = driver.find_elements(By.XPATH, \"//a[starts-with(@href, '/document')]\")\n",
    "    csv_links = []\n",
    "    seen_urls = set()\n",
    "\n",
    "    for a in anchors:\n",
    "        text = a.text.strip()\n",
    "        href = a.get_attribute(\"href\")\n",
    "        if any(name in text for name in link_texts):\n",
    "            full_url = href if href.startswith(\"http\") else \"https://cer.gov.au\" + href\n",
    "            if full_url not in seen_urls:\n",
    "                csv_links.append((text, full_url))\n",
    "                seen_urls.add(full_url)\n",
    "\n",
    "    if not csv_links:\n",
    "        print(\"No CSV links found after clicking all Show buttons.\")\n",
    "    else:\n",
    "        print(\"Found CSV download links:\")\n",
    "        for text, url in csv_links:\n",
    "            print(f\" - {text}: {url}\")\n",
    "\n",
    "        # Download files\n",
    "        for text, url in csv_links:\n",
    "            file_name = url.split(\"/\")[-1] + \".csv\"\n",
    "            print(f\"Downloading '{text}' from {url}\")\n",
    "            resp = requests.get(url)\n",
    "            if resp.status_code == 200:\n",
    "                file_path = os.path.join(data_folder, file_name)\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(resp.content)\n",
    "                print(f\"Saved to: {file_path}\")\n",
    "            else:\n",
    "                print(f\"Failed to download {file_name}, status: {resp.status_code}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Script error:\", e)\n",
    "\n",
    "finally:\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ffc9a",
   "metadata": {},
   "source": [
    "### What this code does\n",
    "\n",
    "- **Prepares output directory**: Ensures a `data` folder exists under `cwd`.\n",
    "- **Defines target reports**: Looks specifically for two ABS report titles:\n",
    "  - “Population and people, ASGS, LGA, and RA, 2011, 2016-2024”\n",
    "  - “Economy and industry, ASGS and LGA, 2011, 2016-2024”\n",
    "- **Configures headless browser**: Starts Chrome headless with a tall window to ensure content loads.\n",
    "\n",
    "### Page navigation and extraction\n",
    "\n",
    "- **Opens ABS methodology page**: Loads `https://www.abs.gov.au/methodologies/data-region-methodology/2011-24` and waits briefly.\n",
    "- **Locates downloadable blocks**: Finds elements with class `file-description-link-formatter`.\n",
    "- **Filters by title**:\n",
    "  - Reads each block’s `<h4>` title.\n",
    "  - If the title matches one of the targets, it proceeds to download.\n",
    "\n",
    "### Downloading files\n",
    "\n",
    "- **Resolves file URL**: Extracts the `<a>` link in the block; prefixes with `https://www.abs.gov.au` if relative.\n",
    "- **Saves content**:\n",
    "  - Performs an HTTP GET.\n",
    "  - On 200 OK, writes the file to `data/<filename>`.\n",
    "  - Logs success; otherwise logs the HTTP status.\n",
    "\n",
    "### Error handling and cleanup\n",
    "\n",
    "- **No matches**: Prints a message if no targeted files were found.\n",
    "- **Exceptions**: Catches and logs any runtime errors.\n",
    "- **Always quits browser**: Closes the headless Chrome in `finally` to free resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "101b0f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found: Population and people, ASGS, LGA, and RA, 2011, 2016-2024\n",
      "Downloading from https://www.abs.gov.au/methodologies/data-region-methodology/2011-24/14100DO0001_2011-24.xlsx\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_folder, file_name)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/response.py:1091\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1090\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1091\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1093\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1094\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/response.py:980\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    978\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 980\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/response.py:904\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    901\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    906\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    907\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    913\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/response.py:887\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    886\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup download folder\n",
    "data_folder = os.path.join(cwd, \"data\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Target report titles to look for\n",
    "target_titles = [\n",
    "    \"Population and people, ASGS, LGA, and RA, 2011, 2016-2024\",\n",
    "    \"Economy and industry, ASGS and LGA, 2011, 2016-2024\"\n",
    "]\n",
    "\n",
    "# Setup headless browser\n",
    "options = Options()\n",
    "options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--window-size=1920,3000\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://www.abs.gov.au/methodologies/data-region-methodology/2011-24\")\n",
    "time.sleep(5)\n",
    "\n",
    "try:\n",
    "    # Find each downloadable file block on the page\n",
    "    blocks = driver.find_elements(By.CLASS_NAME, \"file-description-link-formatter\")\n",
    "\n",
    "    found = 0\n",
    "    for block in blocks:\n",
    "        title_elem = block.find_element(By.TAG_NAME, \"h4\")\n",
    "        title_text = title_elem.text.strip()\n",
    "\n",
    "        if title_text in target_titles:\n",
    "            print(f\"Found: {title_text}\")\n",
    "\n",
    "            download_link = block.find_element(By.TAG_NAME, \"a\")\n",
    "            file_url = download_link.get_attribute(\"href\")\n",
    "            if file_url.startswith(\"/\"):\n",
    "                file_url = \"https://www.abs.gov.au\" + file_url\n",
    "\n",
    "            file_name = file_url.split(\"/\")[-1]\n",
    "            file_path = os.path.join(data_folder, file_name)\n",
    "\n",
    "            print(f\"Downloading from {file_url}\")\n",
    "            r = requests.get(file_url)\n",
    "            if r.status_code == 200:\n",
    "                with open(file_path, \"wb\") as f:\n",
    "                    f.write(r.content)\n",
    "                print(f\"Saved to {file_path}\")\n",
    "                found += 1\n",
    "            else:\n",
    "                print(f\"Failed to download {file_url} (status {r.status_code})\")\n",
    "\n",
    "    if found == 0:\n",
    "        print(\"No matching files found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e680bb5",
   "metadata": {},
   "source": [
    "# Data processing and ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce6a8c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "18e7a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "import uuid\n",
    "import os\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e22888ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas option to avoid FutureWarning for replace\n",
    "pd.set_option('future.no_silent_downcasting', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a47365c",
   "metadata": {},
   "source": [
    "### What this function does\n",
    "\n",
    "- **Loads and cleans NGER CSVs** from the `data` folder and returns a consolidated, cleaned `DataFrame` ready for analysis.\n",
    "\n",
    "### Processing steps\n",
    "\n",
    "- **Validate inputs**:\n",
    "  - Ensures `data/` exists and contains `NGER*.csv` files; otherwise returns an empty `DataFrame`.\n",
    "- **Read and harmonize columns per file**:\n",
    "  - Reads each `NGER*.csv`.\n",
    "  - Detects a state column case-insensitively (any column containing “state”) and renames it to `State`.\n",
    "  - Keeps only available columns from:\n",
    "    - `Reporting entity`, `Facility name`, `State`,\n",
    "    - `Electricity production GJ`, `Total scope 1 emissions t CO2 e`,\n",
    "    - `Total scope 2 emissions t CO2 e`, `Emission intensity t CO2 e MWh`.\n",
    "  - Skips files without a detectable `State` column.\n",
    "- **Combine datasets**:\n",
    "  - Concatenates all per-file subsets into a single `DataFrame`.\n",
    "\n",
    "### Data cleaning rules\n",
    "\n",
    "- **Row filtering**:\n",
    "  - Drops rows with missing `State` or `Emission intensity t CO2 e MWh` (if both columns exist).\n",
    "- **Numeric coercion and imputation**:\n",
    "  - For each of the following columns (if present):\n",
    "    - `Electricity production GJ`\n",
    "    - `Total scope 1 emissions t CO2 e`\n",
    "    - `Total scope 2 emissions t CO2 e`\n",
    "    - `Emission intensity t CO2 e MWh`\n",
    "  - Converts to numeric (`errors='coerce'`), then fills missing values with the mean for that `State`.\n",
    "\n",
    "### Error handling and output\n",
    "\n",
    "- **Resilience**: Logs and skips unreadable/problematic files; continues processing the rest.\n",
    "- **Graceful fallbacks**: Returns an empty `DataFrame` if no valid files were processed or on unexpected errors.\n",
    "- **Success path**: Prints progress messages and returns a copy of the cleaned, stacked `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22de6d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_nger_data():\n",
    "    print(\"Processing NGER data...\")\n",
    "    try:\n",
    "        data_files_path = 'data'\n",
    "        if not os.path.exists(data_files_path):\n",
    "            print(f\"Warning: '{data_files_path}' directory not found. Skipping NGER data processing.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        data_files = [f for f in os.listdir(data_files_path) if f.startswith('NGER') and f.endswith('.csv')]\n",
    "        if not data_files:\n",
    "            print(f\"Warning: No NGER CSV files found in '{data_files_path}' directory. Skipping NGER data processing.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        required_cols = [\n",
    "            'Reporting entity', 'Facility name', 'State',\n",
    "            'Electricity production GJ', 'Total scope 1 emissions t CO2 e',\n",
    "            'Total scope 2 emissions t CO2 e', 'Emission intensity t CO2 e MWh'\n",
    "        ]\n",
    "\n",
    "        all_dfs = []\n",
    "        for file_name in data_files:\n",
    "            file_path = os.path.join(data_files_path, file_name)\n",
    "            try:\n",
    "                df_temp = pd.read_csv(file_path, header=0)\n",
    "                state_col_name = None\n",
    "                for col in df_temp.columns:\n",
    "                    if 'state' in str(col).lower():\n",
    "                        state_col_name = col\n",
    "                        break\n",
    "                if state_col_name:\n",
    "                    df_temp.rename(columns={state_col_name: 'State'}, inplace=True)\n",
    "\n",
    "                    cols_to_keep = [col for col in required_cols if col in df_temp.columns]\n",
    "                    all_dfs.append(df_temp[cols_to_keep])\n",
    "                else:\n",
    "                    print(f\"Warning: No 'State' column found in {file_name}. Skipping.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not read or process file {file_name}. Error: {e}. Skipping.\")\n",
    "\n",
    "        if not all_dfs:\n",
    "            print(\"Warning: No valid NGER files could be processed.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        stacked_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "        if 'State' in stacked_df.columns and 'Emission intensity t CO2 e MWh' in stacked_df.columns:\n",
    "            stacked_df = stacked_df.dropna(subset=['State', 'Emission intensity t CO2 e MWh'])\n",
    "\n",
    "        cols_to_impute = [\n",
    "            'Electricity production GJ', 'Total scope 1 emissions t CO2 e',\n",
    "            'Total scope 2 emissions t CO2 e', 'Emission intensity t CO2 e MWh'\n",
    "        ]\n",
    "        for col in cols_to_impute:\n",
    "            if col in stacked_df.columns:\n",
    "                stacked_df[col] = pd.to_numeric(stacked_df[col], errors='coerce')\n",
    "                stacked_df[col] = stacked_df.groupby('State')[col].transform(lambda x: x.fillna(x.mean()))\n",
    "\n",
    "        print(\"NGER data processed successfully.\")\n",
    "        return stacked_df.copy()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during NGER data processing: {e}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ce2dc",
   "metadata": {},
   "source": [
    "### What this function does\n",
    "\n",
    "- **Geocodes a place name in Australia** using OpenStreetMap Nominatim, returning `(latitude, longitude)` or `(None, None)` if not found.\n",
    "\n",
    "### How it works\n",
    "\n",
    "- **Builds query fallbacks**:\n",
    "  - Full: `\"<name> <state> Australia\"`\n",
    "  - Shortened: `\"<first-word-of-name> <state> Australia\"`\n",
    "  - Optional: `\"Australia postcode <postcode>\"` when provided and non-null.\n",
    "- **Polite request behavior**:\n",
    "  - Sleeps 1 second before each request to respect Nominatim usage policies.\n",
    "  - Sends a custom `User-Agent`.\n",
    "- **Requests and parsing**:\n",
    "  - Calls Nominatim search API with `format=json`, `limit=1`, `countrycodes=au`.\n",
    "  - On 200 OK with at least one result, returns the first result’s `lat`, `lon` as floats.\n",
    "  - Catches exceptions and silently tries the next fallback.\n",
    "\n",
    "### Return value\n",
    "\n",
    "- **Success**: `(lat: float, lon: float)`\n",
    "- **Failure after all fallbacks**: `(None, None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeeb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_with_fallbacks(name, state, postcode=None):\n",
    "    headers = {'User-Agent': 'power-stations-project/1.0 (neerajshetkar@gmail.com)'}\n",
    "    queries = [f\"{name} {state} Australia\", f\"{name.split(' ')[0]} {state} Australia\"]\n",
    "    if postcode and pd.notna(postcode):\n",
    "        queries.append(f\"Australia postcode {postcode}\")\n",
    "    for query in queries:\n",
    "        time.sleep(1)\n",
    "        url = f\"https://nominatim.openstreetmap.org/search?q={quote(query)}&format=json&limit=1&countrycodes=au\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            if response.status_code == 200 and response.json():\n",
    "                result = response.json()[0]\n",
    "                return float(result['lat']), float(result['lon'])\n",
    "        except Exception:\n",
    "            continue\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c98002",
   "metadata": {},
   "source": [
    "### What this function does\n",
    "\n",
    "- **Geocodes a DataFrame of locations** by adding `lat` and `lon` columns using `geocode_with_fallbacks`, and reports how many rows were successfully geocoded.\n",
    "\n",
    "### How it works\n",
    "\n",
    "- **Initializes output columns**: Sets `df['lat']` and `df['lon']` to `None`.\n",
    "- **Iterates over rows**:\n",
    "  - Calls `geocode_with_fallbacks` with `Name_clean`, `State`, and optional `Postcode`.\n",
    "  - If coordinates are returned, writes them into the row and increments a success counter.\n",
    "- **Reports and returns**:\n",
    "  - Prints a summary like `Geocoding complete: X/N successful.`\n",
    "  - Returns the updated `df` and the `successful_geocodes` count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "508befc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geocode_data(df):\n",
    "    df['lat'] = None\n",
    "    df['lon'] = None\n",
    "    successful_geocodes = 0\n",
    "    for i, row in df.iterrows():\n",
    "        lat, lon = geocode_with_fallbacks(row['Name_clean'], row['State'], row.get('Postcode'))\n",
    "        if lat and lon:\n",
    "            df.at[i, 'lat'] = lat\n",
    "            df.at[i, 'lon'] = lon\n",
    "            successful_geocodes += 1\n",
    "    print(f\"Geocoding complete: {successful_geocodes}/{len(df)} successful.\")\n",
    "    return df, successful_geocodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4ff677",
   "metadata": {},
   "source": [
    "### What this function does\n",
    "\n",
    "- **Backfills missing coordinates** by imputing `lat` and `lon` for rows with null `lat` using the state-level mean coordinates.\n",
    "\n",
    "### How it works\n",
    "\n",
    "- **Computes state means**: Groups by `State` and calculates mean `lat`/`lon`.\n",
    "- **Fills nulls**: For each row where `lat` is null, replaces `lat` and `lon` with the corresponding state mean if available.\n",
    "- **Returns**: The updated `DataFrame` with fewer missing coordinates.\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Assumes `lat`/`lon` are numeric or coercible to numeric.\n",
    "- Rows in states with no computed mean remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdf207f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_null_coords(df):\n",
    "    state_coords = df.groupby('State')[['lat', 'lon']].mean()\n",
    "    for i, row in df[df['lat'].isnull()].iterrows():\n",
    "        if row['State'] in state_coords.index:\n",
    "            df.at[i, 'lat'] = state_coords.loc[row['State'], 'lat']\n",
    "            df.at[i, 'lon'] = state_coords.loc[row['State'], 'lon']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765f396",
   "metadata": {},
   "source": [
    "### What this function does\n",
    "\n",
    "- **Loads, standardizes, and enriches CER power station datasets**, then geocodes locations and imputes missing coordinates. Returns a cleaned, consolidated `DataFrame`.\n",
    "\n",
    "### Processing steps\n",
    "\n",
    "- **Load source files**: Reads three CSVs from `data/`:\n",
    "  - `power-stations-and-projects-probable.csv`\n",
    "  - `power-stations-and-projects-committed.csv`\n",
    "  - `power-stations-and-projects-accredited.csv`\n",
    "- **Normalize schema**:\n",
    "  - Renames columns to a common set (`Name`, `State`, `Capacity`, `Fuel`, plus date fields).\n",
    "  - Adds `Status` column with values: `Probable`, `Committed`, `Accredited`.\n",
    "  - Creates `Name_clean` as a trimmed, title-cased version of `Name`.\n",
    "  - Parses date columns (`Committed_Date`, `Accreditation_Start`, `Approval_Date`) with `dd/mm/YYYY`; coerces invalid to `NaT`.\n",
    "  - Normalizes `Postcode` to string and replaces `'nan'` with `None` when present.\n",
    "- **Select and clean fields**:\n",
    "  - Chooses relevant columns per dataset and drops rows with missing `Capacity`.\n",
    "  - Converts `Capacity` to numeric and trims whitespace from `State`.\n",
    "- **Combine and filter**:\n",
    "  - Concatenates all three datasets.\n",
    "  - Keeps only records with `Capacity > 10` MW.\n",
    "\n",
    "### Geospatial enrichment\n",
    "\n",
    "- **Geocode**: Calls `geocode_data(df)` to add `lat`/`lon` using `Name_clean`, `State`, and optional `Postcode`.\n",
    "- **Impute missing coords**: Calls `fill_null_coords(df)` to fill remaining null coordinates with state-level mean latitude/longitude.\n",
    "\n",
    "### Output and errors\n",
    "\n",
    "- **Returns**: The enriched, geocoded `DataFrame`.\n",
    "- **Logs**: Prints progress messages at key steps.\n",
    "- **Error handling**:\n",
    "  - If files not found: warns and returns empty `DataFrame`.\n",
    "  - On other exceptions: logs error and returns empty `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d03bfcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_cer_data():\n",
    "    print(\"Processing CER data...\")\n",
    "    try:\n",
    "        probable_df = pd.read_csv('data/power-stations-and-projects-probable.csv')\n",
    "        committed_df = pd.read_csv('data/power-stations-and-projects-committed.csv')\n",
    "        accredited_df = pd.read_csv('data/power-stations-and-projects-accredited.csv')\n",
    "\n",
    "        probable_df.rename(columns={'Project Name': 'Name', 'State ': 'State', 'MW Capacity': 'Capacity', 'Fuel Source': 'Fuel'}, inplace=True)\n",
    "        committed_df.rename(columns={'Project Name': 'Name', 'State ': 'State', 'MW Capacity': 'Capacity', 'Fuel Source': 'Fuel', 'Committed Date (Month/Year)': 'Committed_Date'}, inplace=True)\n",
    "        accredited_df.rename(columns={'Power station name': 'Name', 'State': 'State', 'Installed capacity (MW)': 'Capacity', 'Fuel Source (s)': 'Fuel', 'Accreditation start date': 'Accreditation_Start', 'Approval date': 'Approval_Date'}, inplace=True)\n",
    "\n",
    "        probable_df['Status'] = 'Probable'\n",
    "        committed_df['Status'] = 'Committed'\n",
    "        accredited_df['Status'] = 'Accredited'\n",
    "\n",
    "        for df in [probable_df, committed_df, accredited_df]:\n",
    "            df['Name_clean'] = df['Name'].str.strip().str.title()\n",
    "            for col in ['Committed_Date', 'Accreditation_Start', 'Approval_Date']:\n",
    "                if col in df.columns:\n",
    "                    df[col] = pd.to_datetime(df[col], format='%d/%m/%Y', errors='coerce')\n",
    "            if 'Postcode' in df.columns:\n",
    "                df['Postcode'] = df['Postcode'].astype(str).replace('nan', None)\n",
    "\n",
    "        probable_df = probable_df[['Name', 'Name_clean', 'State', 'Capacity', 'Fuel', 'Status']].dropna(subset=['Capacity'])\n",
    "        committed_df = committed_df[['Name', 'Name_clean', 'State', 'Capacity', 'Fuel', 'Status', 'Committed_Date']].dropna(subset=['Capacity'])\n",
    "        accredited_df = accredited_df[['Name', 'Name_clean', 'State', 'Capacity', 'Fuel', 'Status', 'Postcode', 'Accreditation_Start', 'Approval_Date']].dropna(subset=['Capacity'])\n",
    "\n",
    "        for df in [probable_df, committed_df, accredited_df]:\n",
    "            df['Capacity'] = pd.to_numeric(df['Capacity'], errors='coerce')\n",
    "            df['State'] = df['State'].str.strip()\n",
    "\n",
    "        df = pd.concat([probable_df, committed_df, accredited_df], ignore_index=True)\n",
    "        df = df[df['Capacity'] > 10].reset_index(drop=True)\n",
    "\n",
    "        print(\"CER data loaded and cleaned. Starting geocoding...\")\n",
    "        df, _ = geocode_data(df)\n",
    "        df = fill_null_coords(df)\n",
    "        print(\"CER data processed successfully.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: CER data files not found in 'Dataset' directory. Skipping CER data processing.\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during CER data processing: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04acd0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing CER data...\n",
      "CER data loaded and cleaned. Starting geocoding...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the CER data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cer_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_clean_cer_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCER DataFrame shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcer_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cer_df\u001b[38;5;241m.\u001b[39mempty:\n",
      "Cell \u001b[0;32mIn[52], line 36\u001b[0m, in \u001b[0;36mload_and_clean_cer_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCapacity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCER data loaded and cleaned. Starting geocoding...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m df, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgeocode_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m df \u001b[38;5;241m=\u001b[39m fill_null_coords(df)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCER data processed successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 6\u001b[0m, in \u001b[0;36mgeocode_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m successful_geocodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 6\u001b[0m     lat, lon \u001b[38;5;241m=\u001b[39m \u001b[43mgeocode_with_fallbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName_clean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mState\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPostcode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lat \u001b[38;5;129;01mand\u001b[39;00m lon:\n\u001b[1;32m      8\u001b[0m         df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lat\n",
      "Cell \u001b[0;32mIn[48], line 10\u001b[0m, in \u001b[0;36mgeocode_with_fallbacks\u001b[0;34m(name, state, postcode)\u001b[0m\n\u001b[1;32m      8\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://nominatim.openstreetmap.org/search?q=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(query)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&format=json&limit=1&countrycodes=au\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson():\n\u001b[1;32m     12\u001b[0m         result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load CER data without geocoding (faster alternative)\n",
    "print(\"Loading CER data with approximate state-level coordinates...\")\n",
    "try:\n",
    "    probable_df = pd.read_csv('data/power-stations-and-projects-probable.csv')\n",
    "    committed_df = pd.read_csv('data/power-stations-and-projects-committed.csv')\n",
    "    accredited_df = pd.read_csv('data/power-stations-and-projects-accredited.csv')\n",
    "\n",
    "    # Standardize columns\n",
    "    probable_df.rename(columns={'Project Name': 'Name', 'State ': 'State', 'MW Capacity': 'Capacity', 'Fuel Source': 'Fuel'}, inplace=True)\n",
    "    committed_df.rename(columns={'Project Name': 'Name', 'State ': 'State', 'MW Capacity': 'Capacity', 'Fuel Source': 'Fuel'}, inplace=True)\n",
    "    accredited_df.rename(columns={'Power station name': 'Name', 'State': 'State', 'Installed capacity (MW)': 'Capacity', 'Fuel Source (s)': 'Fuel'}, inplace=True)\n",
    "\n",
    "    probable_df['Status'] = 'Probable'\n",
    "    committed_df['Status'] = 'Committed'\n",
    "    accredited_df['Status'] = 'Accredited'\n",
    "\n",
    "    # Combine datasets\n",
    "    cer_df = pd.concat([probable_df, committed_df, accredited_df], ignore_index=True)\n",
    "    cer_df['Capacity'] = pd.to_numeric(cer_df['Capacity'], errors='coerce')\n",
    "    cer_df['State'] = cer_df['State'].str.strip()\n",
    "    cer_df = cer_df[cer_df['Capacity'] > 10].reset_index(drop=True)\n",
    "    \n",
    "    # Add approximate state-level coordinates (capital city locations)\n",
    "    state_coords = {\n",
    "        'NSW': (-33.8688, 151.2093),\n",
    "        'VIC': (-37.8136, 144.9631),\n",
    "        'QLD': (-27.4698, 153.0251),\n",
    "        'SA': (-34.9285, 138.6007),\n",
    "        'WA': (-31.9505, 115.8605),\n",
    "        'TAS': (-42.8821, 147.3272),\n",
    "        'NT': (-12.4634, 130.8456),\n",
    "        'ACT': (-35.2809, 149.1300)\n",
    "    }\n",
    "    \n",
    "    cer_df['lat'] = cer_df['State'].map(lambda s: state_coords.get(s, (None, None))[0])\n",
    "    cer_df['lon'] = cer_df['State'].map(lambda s: state_coords.get(s, (None, None))[1])\n",
    "    \n",
    "    print(f\"✓ CER data loaded: {len(cer_df)} power stations\")\n",
    "    print(f\"✓ Columns: {list(cer_df.columns)}\")\n",
    "    print(f\"✓ Coordinates added: {cer_df['lat'].notna().sum()}/{len(cer_df)} stations\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading CER data: {e}\")\n",
    "    cer_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677ff39a",
   "metadata": {},
   "source": [
    "### What this function does\n",
    "\n",
    "- **Loads and cleans ABS population tables** from an Excel workbook, standardizes their schema, imputes missing numeric values, and returns a combined `DataFrame`.\n",
    "\n",
    "### Processing steps\n",
    "\n",
    "- **File check**: Verifies `data/14100DO0001_2011-24.xlsx` exists; otherwise returns an empty `DataFrame`.\n",
    "- **Read sheets**: Loads “Table 1”, “Table 2”, and “Table 3” with `skiprows=5`.\n",
    "\n",
    "### Cleaning logic per sheet (`clean_df`)\n",
    "\n",
    "- **Header normalization**:\n",
    "  - Uses the first data row as headers, then resets rows.\n",
    "  - Slugifies headers to lowercase with underscores.\n",
    "  - Renames first two columns to `label` and `code`.\n",
    "- **Row filtering**:\n",
    "  - Keeps rows with non-null `code` and excludes notes/copyright rows.\n",
    "- **Type handling**:\n",
    "  - If present, converts `year` to nullable integer.\n",
    "  - Replaces `\"-\"` and `\"nil\"` with `NaN`.\n",
    "  - Converts non-identifier object columns to numeric (coercing errors to `NaN`).\n",
    "- **Imputation**:\n",
    "  - For each numeric column, fills `NaN` with the mean within the same `label`.\n",
    "- **Final filter**:\n",
    "  - Drops rows where `year` is missing.\n",
    "\n",
    "### Output\n",
    "\n",
    "- **Concatenates** the three cleaned tables into `abs_df` and returns it.\n",
    "- **Error handling**: On any exception, logs and returns an empty `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:00:06.169660Z",
     "start_time": "2025-09-26T12:00:06.166145Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_clean_abs_data():\n",
    "    print(\"Processing ABS data...\")\n",
    "    try:\n",
    "        pop_file = \"data/14100DO0001_2011-24.xlsx\"\n",
    "        if not os.path.exists(pop_file):\n",
    "            print(\"Warning: ABS data file not found. Skipping ABS data processing.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        pop_table1 = pd.read_excel(pop_file, sheet_name=\"Table 1\", skiprows=5)\n",
    "        pop_table2 = pd.read_excel(pop_file, sheet_name=\"Table 2\", skiprows=5)\n",
    "        pop_table3 = pd.read_excel(pop_file, sheet_name=\"Table 3\", skiprows=5)\n",
    "\n",
    "        def clean_df(df):\n",
    "            if df.empty: return df\n",
    "            df.columns = df.iloc[0]\n",
    "            df = df[1:].reset_index(drop=True)\n",
    "            df.columns = [str(col).strip().lower().replace(\" \", \"_\") for col in df.columns]\n",
    "            df = df.rename(columns={df.columns[0]: \"label\", df.columns[1]: \"code\"})\n",
    "            df = df[df[\"code\"].notna() & ~df[\"code\"].astype(str).str.contains(\"Note|©\", na=False)]\n",
    "            if 'year' in df.columns:\n",
    "                df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "            df = df.replace([\"-\", \"nil\"], np.nan)\n",
    "            for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "                if col not in [\"label\", \"code\"]:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            for col in df.select_dtypes(include=\"number\").columns:\n",
    "                df[col] = df.groupby(\"label\")[col].transform(lambda x: x.fillna(x.mean()))\n",
    "            return df.dropna(subset=['year'])  # Changed from dropna() to dropna(subset=['year'])\n",
    "\n",
    "        pop_table1 = clean_df(pop_table1)\n",
    "        pop_table2 = clean_df(pop_table2)\n",
    "        pop_table3 = clean_df(pop_table3)\n",
    "\n",
    "        abs_df = pd.concat([pop_table1, pop_table2, pop_table3], ignore_index=True)\n",
    "        print(\"ABS data processed successfully.\")\n",
    "        return abs_df\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during ABS data processing: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca9dfe",
   "metadata": {},
   "source": [
    "### What this function does\n",
    "\n",
    "- **Builds and populates a DuckDB database** (`australian_electricity_data.db`) with standardized tables for states, fuels, power stations, emissions, and ABS demographics, including geospatial points.\n",
    "\n",
    "### Steps and tables created\n",
    "\n",
    "- **Init and extensions**\n",
    "  - Connects to DuckDB, installs/loads `spatial` for geometry support.\n",
    "\n",
    "- **States**\n",
    "  - Creates `states(state_id, state_code, state_name)`.\n",
    "  - Extracts unique state codes from `NGER` and `CER` inputs, maps to full names, and upserts.\n",
    "\n",
    "- **Fuels**\n",
    "  - If `CER` has `Fuel`, creates `fuels(fuel_id, fuel_type)` and inserts unique fuels.\n",
    "\n",
    "- **Power stations**\n",
    "  - If `CER` is non-empty, creates `power_stations(...)` with:\n",
    "    - UUID `station_id`, `name`, `capacity_mw`, `status`\n",
    "    - `latitude`, `longitude`, `geom` as `ST_Point(lon, lat)` when both present\n",
    "    - Foreign keys to `states(state_id)` and `fuels(fuel_id)`\n",
    "  - Maps `State` and `Fuel` to their IDs and inserts all rows.\n",
    "\n",
    "- **Emissions**\n",
    "  - If `NGER` is non-empty, creates `emissions(...)` with:\n",
    "    - UUID `emission_id`, `reporting_entity`, `facility_name`,\n",
    "      `electricity_production_gj`, `scope1_emissions_t_co2e`, `scope2_emissions_t_co2e`\n",
    "    - `state_id` as FK\n",
    "  - Maps `State` to `state_id` and inserts.\n",
    "\n",
    "- **ABS demographics**\n",
    "  - If `ABS` is non-empty, creates `abs_demographics(...)` with:\n",
    "    - UUID `demographic_id`, `year`, `metric_name`, `metric_value`, `state_id` (FK)\n",
    "  - Melts numeric columns into long format, drops nulls, heuristically assigns `state_code` by matching `label` to state names/codes, and bulk inserts.\n",
    "\n",
    "- **Finalize**\n",
    "  - Prints success messages and closes the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b474062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_populate_database(nger_df, cer_df, abs_df):\n",
    "    print(\"Creating and populating the database...\")\n",
    "    con = duckdb.connect('australian_electricity_data.db')\n",
    "    con.execute(\"INSTALL spatial; LOAD spatial;\")\n",
    "    con.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS states (\n",
    "        state_id VARCHAR PRIMARY KEY,\n",
    "        state_code VARCHAR UNIQUE,\n",
    "        state_name VARCHAR\n",
    "    )\n",
    "    \"\"\")\n",
    "    state_mapping = {'NSW': 'New South Wales', 'VIC': 'Victoria', 'QLD': 'Queensland', 'SA': 'South Australia', 'WA': 'Western Australia', 'TAS': 'Tasmania', 'NT': 'Northern Territory', 'ACT': 'Australian Capital Territory'}\n",
    "    all_states = set()\n",
    "    if not nger_df.empty and 'State' in nger_df.columns: all_states.update(nger_df['State'].unique())\n",
    "    if not cer_df.empty and 'State' in cer_df.columns: all_states.update(cer_df['State'].unique())\n",
    "    state_data = [(str(uuid.uuid4()), code, state_mapping.get(code)) for code in all_states if code in state_mapping]\n",
    "    if state_data:\n",
    "        states_df = pd.DataFrame(state_data, columns=['state_id', 'state_code', 'state_name'])\n",
    "        con.register('states_view', states_df)\n",
    "        con.execute(\"\"\"\n",
    "            INSERT INTO states (state_id, state_code, state_name)\n",
    "            SELECT state_id, state_code, state_name FROM states_view\n",
    "            ON CONFLICT (state_code) DO NOTHING\n",
    "        \"\"\")\n",
    "        con.unregister('states_view')\n",
    "\n",
    "    state_ids = dict(con.execute(\"SELECT state_code, state_id FROM states\").fetchall())\n",
    "\n",
    "    if not cer_df.empty and 'Fuel' in cer_df.columns:\n",
    "        con.execute(\"CREATE TABLE IF NOT EXISTS fuels (fuel_id VARCHAR PRIMARY KEY, fuel_type VARCHAR UNIQUE)\")\n",
    "\n",
    "        fuel_data = [(str(uuid.uuid4()), fuel) for fuel in cer_df['Fuel'].unique() if pd.notna(fuel)]\n",
    "        if fuel_data:\n",
    "            fuels_df = pd.DataFrame(fuel_data, columns=['fuel_id', 'fuel_type'])\n",
    "            con.register('fuels_view', fuels_df)\n",
    "            con.execute(\"\"\"\n",
    "                INSERT INTO fuels (fuel_id, fuel_type)\n",
    "                SELECT fuel_id, fuel_type FROM fuels_view\n",
    "                ON CONFLICT (fuel_type) DO NOTHING\n",
    "            \"\"\")\n",
    "            con.unregister('fuels_view')\n",
    "        fuel_ids = dict(con.execute(\"SELECT fuel_type, fuel_id FROM fuels\").fetchall())\n",
    "    if not cer_df.empty:\n",
    "        con.execute(\"\"\"\n",
    "        CREATE OR REPLACE TABLE power_stations (\n",
    "            station_id VARCHAR PRIMARY KEY, name VARCHAR, capacity_mw FLOAT, status VARCHAR,\n",
    "            latitude FLOAT, longitude FLOAT, geom GEOMETRY,\n",
    "            state_id VARCHAR REFERENCES states(state_id), fuel_id VARCHAR REFERENCES fuels(fuel_id)\n",
    "        )\n",
    "        \"\"\")\n",
    "        ps_df = cer_df.copy()\n",
    "        ps_df['station_id'] = [str(uuid.uuid4()) for _ in range(len(ps_df))]\n",
    "        ps_df['state_id'] = ps_df['State'].map(state_ids)\n",
    "        ps_df['fuel_id'] = ps_df['Fuel'].map(fuel_ids)\n",
    "\n",
    "        con.register('ps_view', ps_df)\n",
    "        con.execute(\"\"\"\n",
    "            INSERT INTO power_stations\n",
    "            SELECT\n",
    "                station_id, Name AS name, Capacity AS capacity_mw, Status AS status,\n",
    "                lat AS latitude, lon AS longitude,\n",
    "                CASE WHEN lon IS NOT NULL AND lat IS NOT NULL THEN ST_Point(lon, lat) ELSE NULL END AS geom,\n",
    "                state_id, fuel_id\n",
    "            FROM ps_view\n",
    "        \"\"\")\n",
    "        con.unregister('ps_view')\n",
    "\n",
    "    if not nger_df.empty:\n",
    "        con.execute(\"\"\"\n",
    "        CREATE OR REPLACE TABLE emissions (\n",
    "            emission_id VARCHAR PRIMARY KEY, reporting_entity VARCHAR, facility_name VARCHAR,\n",
    "            electricity_production_gj FLOAT, scope1_emissions_t_co2e FLOAT,\n",
    "            scope2_emissions_t_co2e FLOAT, state_id VARCHAR REFERENCES states(state_id)\n",
    "        )\n",
    "        \"\"\")\n",
    "        emissions_df = nger_df.copy()\n",
    "        emissions_df['emission_id'] = [str(uuid.uuid4()) for _ in range(len(emissions_df))]\n",
    "        emissions_df['state_id'] = emissions_df['State'].map(state_ids)\n",
    "\n",
    "        # Rename columns to match SQL identifiers (no spaces, lowercase, underscores)\n",
    "        rename_map = {\n",
    "            \"Reporting entity\": \"reporting_entity\",\n",
    "            \"Facility name\": \"facility_name\",\n",
    "            \"Electricity production GJ\": \"electricity_production_gj\",\n",
    "            \"Total scope 1 emissions t CO2 e\": \"scope1_emissions_t_co2e\",\n",
    "            \"Total scope 2 emissions t CO2 e\": \"scope2_emissions_t_co2e\"\n",
    "        }\n",
    "        # Only rename if columns exist\n",
    "        for old, new in rename_map.items():\n",
    "            if old in emissions_df.columns:\n",
    "                emissions_df.rename(columns={old: new}, inplace=True)\n",
    "\n",
    "        # Ensure all required columns exist\n",
    "        required_cols = [\n",
    "            \"emission_id\", \"reporting_entity\", \"facility_name\",\n",
    "            \"electricity_production_gj\", \"scope1_emissions_t_co2e\",\n",
    "            \"scope2_emissions_t_co2e\", \"state_id\"\n",
    "        ]\n",
    "        missing_cols = [col for col in required_cols if col not in emissions_df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Warning: The following columns are missing in NGER data and will be filled with None: {missing_cols}\")\n",
    "            for col in missing_cols:\n",
    "                emissions_df[col] = None\n",
    "\n",
    "        con.register('emissions_view', emissions_df)\n",
    "        con.execute(\"\"\"\n",
    "            INSERT INTO emissions\n",
    "            SELECT\n",
    "                emission_id, reporting_entity, facility_name, electricity_production_gj,\n",
    "                scope1_emissions_t_co2e, scope2_emissions_t_co2e, state_id\n",
    "            FROM emissions_view\n",
    "        \"\"\")\n",
    "        con.unregister('emissions_view')\n",
    "\n",
    "    if not abs_df.empty:\n",
    "        con.execute(\"\"\"\n",
    "        CREATE OR REPLACE TABLE abs_demographics (\n",
    "            demographic_id VARCHAR PRIMARY KEY, year INTEGER, metric_name VARCHAR,\n",
    "            metric_value FLOAT, state_id VARCHAR REFERENCES states(state_id)\n",
    "        )\n",
    "        \"\"\")\n",
    "        numeric_cols = [col for col in abs_df.columns if col not in ['label', 'code', 'year'] and abs_df[col].dtype in ['float64', 'int64', 'Int64']]\n",
    "        if numeric_cols:\n",
    "            abs_melted = abs_df.melt(id_vars=['label', 'code', 'year'], value_vars=numeric_cols, var_name='metric_name', value_name='metric_value')\n",
    "            abs_melted = abs_melted.dropna(subset=['metric_value'])  # Remove rows with null values\n",
    "            \n",
    "            abs_data = []\n",
    "            for _, row in abs_melted.iterrows():\n",
    "                state_code = None\n",
    "                label_lower = str(row['label']).lower()\n",
    "                for code, name in state_mapping.items():\n",
    "                    if name.lower() in label_lower or code.lower() in label_lower:\n",
    "                        state_code = code\n",
    "                        break\n",
    "                \n",
    "                if state_code and state_ids.get(state_code) and pd.notna(row.get('metric_value')):\n",
    "                    abs_data.append((\n",
    "                        str(uuid.uuid4()), \n",
    "                        int(row.get('year')) if pd.notna(row.get('year')) else None, \n",
    "                        str(row.get('metric_name')), \n",
    "                        float(row.get('metric_value')), \n",
    "                        state_ids.get(state_code)\n",
    "                    ))\n",
    "            \n",
    "            if abs_data: \n",
    "                con.executemany(\"INSERT INTO abs_demographics (demographic_id, year, metric_name, metric_value, state_id) VALUES (?, ?, ?, ?, ?)\", abs_data)\n",
    "                print(f\"Inserted {len(abs_data)} ABS demographic records.\")\n",
    "\n",
    "    print(\"Database created and populated successfully.\")\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a07f3",
   "metadata": {},
   "source": [
    "### What this code does\n",
    "\n",
    "- **Verifies the database**:\n",
    "  - Checks that `australian_electricity_data.db` exists.\n",
    "  - Connects to DuckDB, lists all tables, and prints the first 5 rows from each.\n",
    "  - Catches and reports read errors per table, then closes the connection.\n",
    "\n",
    "### Script entrypoint workflow\n",
    "\n",
    "- **Runs data pipelines**:\n",
    "  - Calls `load_and_clean_nger_data()`, `load_and_clean_cer_data()`, and `load_and_clean_abs_data()`.\n",
    "- **Conditional database build**:\n",
    "  - If all three are empty, prints a halt message.\n",
    "  - Otherwise, calls `create_and_populate_database(...)`, then `verify_database()` to preview contents, and prints a completion message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765f5a4797f58b51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T12:10:37.905392Z",
     "start_time": "2025-09-26T12:00:06.308327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing NGER data...\n",
      "NGER data processed successfully.\n",
      "Processing CER data...\n",
      "CER data loaded and cleaned. Starting geocoding...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     18\u001b[0m     nger_df \u001b[38;5;241m=\u001b[39m load_and_clean_nger_data()\n\u001b[0;32m---> 19\u001b[0m     cer_df \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_clean_cer_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     abs_df \u001b[38;5;241m=\u001b[39m load_and_clean_abs_data()\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nger_df\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mand\u001b[39;00m cer_df\u001b[38;5;241m.\u001b[39mempty \u001b[38;5;129;01mand\u001b[39;00m abs_df\u001b[38;5;241m.\u001b[39mempty:\n",
      "Cell \u001b[0;32mIn[35], line 36\u001b[0m, in \u001b[0;36mload_and_clean_cer_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCapacity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCER data loaded and cleaned. Starting geocoding...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m df, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgeocode_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m df \u001b[38;5;241m=\u001b[39m fill_null_coords(df)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCER data processed successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 6\u001b[0m, in \u001b[0;36mgeocode_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      4\u001b[0m successful_geocodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 6\u001b[0m     lat, lon \u001b[38;5;241m=\u001b[39m \u001b[43mgeocode_with_fallbacks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mName_clean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mState\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPostcode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lat \u001b[38;5;129;01mand\u001b[39;00m lon:\n\u001b[1;32m      8\u001b[0m         df\u001b[38;5;241m.\u001b[39mat[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lat\n",
      "Cell \u001b[0;32mIn[32], line 10\u001b[0m, in \u001b[0;36mgeocode_with_fallbacks\u001b[0;34m(name, state, postcode)\u001b[0m\n\u001b[1;32m      8\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://nominatim.openstreetmap.org/search?q=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(query)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&format=json&limit=1&countrycodes=au\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson():\n\u001b[1;32m     12\u001b[0m         result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/urllib3/connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:1349\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1349\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:316\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 316\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/http/client.py:277\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 277\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1238\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1239\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1240\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def verify_database():\n",
    "    db_file = 'australian_electricity_data.db'\n",
    "    if not os.path.exists(db_file):\n",
    "        print(f\"Database file '{db_file}' not found. Cannot verify.\")\n",
    "        return\n",
    "    print(\"\\nVerifying database contents...\")\n",
    "    con = duckdb.connect(db_file)\n",
    "    tables = con.execute(\"SHOW TABLES\").fetchdf()['name'].tolist()\n",
    "    for table in tables:\n",
    "        print(f\"\\n--- Contents of {table} table (first 5 rows) ---\")\n",
    "        try:\n",
    "            print(con.execute(f\"SELECT * FROM {table} LIMIT 5\").fetchdf())\n",
    "        except Exception as e:\n",
    "            print(f\"Could not read from table {table}. Error: {e}\")\n",
    "    con.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nger_df = load_and_clean_nger_data()\n",
    "    cer_df = load_and_clean_cer_data()\n",
    "    abs_df = load_and_clean_abs_data()\n",
    "\n",
    "    if nger_df.empty and cer_df.empty and abs_df.empty:\n",
    "        print(\"\\nNo data was processed. Halting database creation.\")\n",
    "    else:\n",
    "        create_and_populate_database(nger_df, cer_df, abs_df)\n",
    "        verify_database()\n",
    "        print(\"\\nProcess complete! Database 'australian_electricity_data.db' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa00284",
   "metadata": {},
   "source": [
    "### What this function does\n",
    "\n",
    "- **Explores CER data and visualizes capacity by fuel type**. Saves a bar chart and prints a capacity summary.\n",
    "\n",
    "### Steps\n",
    "\n",
    "- **Guard**: Skips if `cer_df` is empty.\n",
    "- **Aggregate**: Groups by `Fuel` and sums `Capacity`, sorted descending.\n",
    "- **Report**: Prints the total capacity per fuel source.\n",
    "- **Visualize**:\n",
    "  - Creates a bar chart using a Viridis palette.\n",
    "  - Titles and labels axes; rotates x-axis labels; applies `seaborn`-style grid.\n",
    "  - Saves to `capacity_by_fuel_type.png` and displays the plot.\n",
    "- **Finish**: Prints completion message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38b93e8",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e55d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Exploration: CER DataFrame is empty. Skipping visualization.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def explore_and_visualize_data(cer_df):\n",
    "    \"\"\"\n",
    "    Performs data exploration on the cleaned CER data and generates a visualization.\n",
    "    \"\"\"\n",
    "    if cer_df.empty:\n",
    "        print(\"\\nData Exploration: CER DataFrame is empty. Skipping visualization.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Starting Data Exploration ---\")\n",
    "\n",
    "    fuel_capacity = cer_df.groupby('Fuel')['Capacity'].sum().sort_values(ascending=False)\n",
    "\n",
    "    print(\"\\nKey Finding: Total Power Generation Capacity (MW) by Fuel Source:\")\n",
    "    print(fuel_capacity)\n",
    "\n",
    "    # --- Data Visualization: Bar Chart of Capacity by Fuel Type ---\n",
    "    print(\"\\nGenerating visualization...\")\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "    fuel_capacity.plot(kind='bar', ax=ax, color=sns.color_palette(\"viridis\", len(fuel_capacity)))\n",
    "\n",
    "    ax.set_title('Total Power Generation Capacity (MW) by Fuel Type in Australia', fontsize=16, weight='bold')\n",
    "    ax.set_xlabel('Fuel Type', fontsize=12)\n",
    "    ax.set_ylabel('Total Capacity (MW)', fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45, labelsize=10)\n",
    "    ax.tick_params(axis='y', labelsize=10)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure to a file\n",
    "    plt.savefig('capacity_by_fuel_type.png')\n",
    "    print(\"Visualization saved as 'capacity_by_fuel_type.png'\")\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "\n",
    "explore_and_visualize_data(cer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8f90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Exploration: CER DataFrame is empty or missing coordinate columns. Skipping map visualization.\n"
     ]
    }
   ],
   "source": [
    "def explore_and_visualize_map(cer_df):\n",
    "    if cer_df.empty or 'lat' not in cer_df.columns or 'lon' not in cer_df.columns:\n",
    "        print(\"\\nData Exploration: CER DataFrame is empty or missing coordinate columns. Skipping map visualization.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Starting Data Exploration for Map Visualization ---\")\n",
    "\n",
    "    df_map = cer_df.dropna(subset=['lat', 'lon', 'Fuel']).copy()\n",
    "\n",
    "    # --- Data Visualization: Interactive Map ---\n",
    "    print(\"Generating interactive map...\")\n",
    "\n",
    "    # Create a color palette for the different fuel types\n",
    "    unique_fuels = sorted(df_map['Fuel'].unique())\n",
    "    colors = [\n",
    "        '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd',\n",
    "        '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'\n",
    "    ]\n",
    "    color_map = {fuel: colors[i % len(colors)] for i, fuel in enumerate(unique_fuels)}\n",
    "    df_map['color'] = df_map['Fuel'].map(color_map)\n",
    "\n",
    "    # Initialize map centered on Australia\n",
    "    aus_map = folium.Map(location=[-25.2744, 133.7751], zoom_start=4)\n",
    "\n",
    "    # Use MarkerCluster for better performance with many points\n",
    "    marker_cluster = MarkerCluster().add_to(aus_map)\n",
    "\n",
    "    # Add points to the map\n",
    "    for idx, row in df_map.iterrows():\n",
    "        popup_html = f\"\"\"\n",
    "        <b>Name:</b> {row['Name']}<br>\n",
    "        <b>Capacity (MW):</b> {row['Capacity']}<br>\n",
    "        <b>Fuel:</b> {row['Fuel']}<br>\n",
    "        <b>Status:</b> {row['Status']}\n",
    "        \"\"\"\n",
    "        iframe = folium.IFrame(popup_html, width=250, height=100)\n",
    "        popup = folium.Popup(iframe, max_width=250)\n",
    "\n",
    "        folium.CircleMarker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            radius=5,\n",
    "            popup=popup,\n",
    "            color=row['color'],\n",
    "            fill=True,\n",
    "            fill_color=row['color'],\n",
    "            fill_opacity=0.7\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "    # --- Add a Legend ---\n",
    "    legend_html = '''\n",
    "    <div style=\"position: fixed;\n",
    "                bottom: 50px; left: 50px; width: 180px; height: auto;\n",
    "                border:2px solid grey; z-index:9999; font-size:14px;\n",
    "                background-color:white; padding: 10px;\">\n",
    "    <b>Fuel Types</b><br>\n",
    "    '''\n",
    "    for fuel, color in color_map.items():\n",
    "        legend_html += f'<i class=\"fa fa-circle\" style=\"color:{color}\"></i> {fuel}<br>'\n",
    "    legend_html += '</div>'\n",
    "    aus_map.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    # Display the map inline in the notebook\n",
    "    from IPython.display import HTML\n",
    "    map_html = aus_map._repr_html_()\n",
    "    display(HTML(map_html))\n",
    "    print(\"\\n--- Map Visualization Complete ---\")\n",
    "\n",
    "explore_and_visualize_map(cer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f071aad",
   "metadata": {},
   "source": [
    "### AI usage acknowledgement\n",
    "\n",
    "This project used AI assistance from ChatGPT (GPT‑5) to help diagnose and fix code issues, improve code quality, and draft concise documentation of functions and workflows. All outputs were reviewed, tested, and integrated by the group."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
